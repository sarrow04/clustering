# -*- coding: utf-8 -*-
"""clustering_app.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WAG_Dan5KaR2tcXuiHZP4cpSSioCM6i3
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import io

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ”¯æ´ã‚¢ãƒ—ãƒª",
    page_icon="ğŸ§©",
    layout="wide"
)

# --- é–¢æ•° ---
def convert_df_to_csv(df):
    """DataFrameã‚’CSVå½¢å¼ã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹ (æ–‡å­—åŒ–ã‘å¯¾ç­–æ¸ˆã¿)"""
    return df.to_csv(index=False).encode('utf-8-sig')

@st.cache_data
def calculate_clustering_scores(scaled_data, max_k):
    """ã‚¨ãƒ«ãƒœãƒ¼æ³•ã¨ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹"""
    wcss = []
    silhouette_scores = []
    k_range = range(2, max_k + 1)

    for k in k_range:
        kmeans = KMeans(n_clusters=k, init='k-means++', n_init='auto', random_state=42)
        kmeans.fit(scaled_data)
        wcss.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(scaled_data, kmeans.labels_))

    return k_range, wcss, silhouette_scores

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("ğŸ§© K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ”¯æ´ã‚¢ãƒ—ãƒª")
st.write("ãƒ‡ãƒ¼ã‚¿ã®æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—æ•°ï¼‰ã‚’è©•ä¾¡ã—ã€å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘ã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("1. ãƒ‡ãƒ¼ã‚¿æº–å‚™")
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
    
    # dfã¨selected_colsã‚’åˆæœŸåŒ–
    df = None
    selected_cols = []

    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        
        # --- ã“ã“ã‹ã‚‰ãŒè¿½åŠ æ©Ÿèƒ½ ---
        with st.expander("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ä¸­èº«ã‚’ç¢ºèª ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
            st.dataframe(df.head())
        # --- ã“ã“ã¾ã§ãŒè¿½åŠ æ©Ÿèƒ½ ---

        st.subheader("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ã†åˆ—ã‚’é¸æŠ")
        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        
        selected_cols = st.multiselect(
            "æ•°å€¤å‹ã®åˆ—ã‹ã‚‰è¤‡æ•°é¸æŠã—ã¦ãã ã•ã„",
            options=numeric_cols,
            default=numeric_cols[:min(len(numeric_cols), 3)]
        )

# --- ã‚¢ãƒ—ãƒªæœ¬ä½“ ---
if df is not None and selected_cols:
    st.header("2. æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®è©•ä¾¡")

    # é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰
    data_to_cluster = df[selected_cols].dropna()
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(data_to_cluster)

    max_k = st.slider("è©•ä¾¡ã™ã‚‹æœ€å¤§ã‚¯ãƒ©ã‚¹ã‚¿æ•°(K)", min_value=5, max_value=20, value=10)

    if st.button("è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹"):
        with st.spinner("ã‚¨ãƒ«ãƒœãƒ¼æ³•ã¨ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ä¸­..."):
            k_range, wcss, silhouette_scores = calculate_clustering_scores(scaled_data, max_k)

            # çµæœã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ã‚¨ãƒ«ãƒœãƒ¼æ³•")
                fig, ax = plt.subplots()
                ax.plot(k_range, wcss, marker='o')
                ax.set_xlabel("ã‚¯ãƒ©ã‚¹ã‚¿æ•° (K)")
                ax.set_ylabel("ã‚¯ãƒ©ã‚¹ã‚¿å†…èª¤å·®å¹³æ–¹å’Œ (WCSS)")
                ax.set_title("Elbow Method")
                st.pyplot(fig)
                st.info("ã‚°ãƒ©ãƒ•ãŒã€Œè‚˜ã€ã®ã‚ˆã†ã«æ€¥ã«æ›²ãŒã‚‹ç‚¹ãŒã€æœ€é©ãªKã®å€™è£œã§ã™ã€‚")

            with col2:
                st.subheader("ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢")
                fig, ax = plt.subplots()
                ax.plot(k_range, silhouette_scores, marker='o')
                ax.set_xlabel("ã‚¯ãƒ©ã‚¹ã‚¿æ•° (K)")
                ax.set_ylabel("å¹³å‡ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢")
                ax.set_title("Silhouette Score")
                st.pyplot(fig)
                st.info("ã‚¹ã‚³ã‚¢ãŒæœ€ã‚‚é«˜ããªã‚‹ç‚¹ãŒã€æœ€é©ãªKã®å€™è£œã§ã™ã€‚")

    st.markdown("---")
    st.header("3. ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®å®Ÿè¡Œã¨åˆ†æ")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ€é©ãªKã‚’å…¥åŠ›
    final_k = st.number_input("ã‚°ãƒ©ãƒ•ã‚’å‚è€ƒã«ã€æœ€çµ‚çš„ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", min_value=2, max_value=max_k, value=3)

    if st.button("ã“ã®ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã§å®Ÿè¡Œ"):
        # æœ€çµ‚çš„ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        kmeans = KMeans(n_clusters=final_k, init='k-means++', n_init='auto', random_state=42)
        clusters = kmeans.fit_predict(scaled_data)

        # çµæœã‚’å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
        df_clustered = df.copy()
        # dropna()ã§æ¬ æè¡Œã‚’é™¤å¤–ã—ãŸãŸã‚ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆã‚ã›ã¦è¿½åŠ 
        df_clustered.loc[data_to_cluster.index, 'cluster'] = clusters

        st.subheader(f"{final_k}å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†é¡ã—ã¾ã—ãŸ")
        st.dataframe(df_clustered.head())

        # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´ã‚’åˆ†æ
        st.subheader("å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‰¹å¾´")
        # .copy() ã‚’ä½¿ã£ã¦SettingWithCopyWarningã‚’å›é¿
        cluster_summary = df_clustered.dropna(subset=['cluster']).copy()
        cluster_summary['cluster'] = cluster_summary['cluster'].astype(int)

        st.dataframe(cluster_summary.groupby('cluster')[selected_cols].mean())

        st.subheader("å„ã‚¯ãƒ©ã‚¹ã‚¿ã®æ‰€å±äººæ•°")
        st.dataframe(cluster_summary['cluster'].value_counts().sort_index())

        st.download_button(
           label="ã‚¯ãƒ©ã‚¹ã‚¿ä»˜ãCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
           data=convert_df_to_csv(df_clustered),
           file_name='data_with_clusters.csv',
           mime='text/csv',
        )
else:
    st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ†æã«ä½¿ã†åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
